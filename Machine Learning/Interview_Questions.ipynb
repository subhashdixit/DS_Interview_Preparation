{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you handle missing data in a dataset?\n",
    "Missing data can be a problem in datasets. One way to handle it is by filling the missing values with the mean, median, or mode of the existing data for that column. Another approach is to remove the rows with missing values, but this might lead to a loss of valuable information.\n",
    "Example:\n",
    "Let's consider a dataset of ages with some missing values:\n",
    "[25, 30, 35, NaN, 28, NaN, 40, 45]\n",
    "To handle missing data, we can fill the NaN values with the mean of the known ages:\n",
    "[25, 30, 35, 34.5, 28, 34.5, 40, 45]\n",
    "Can you explain the difference between supervised and unsupervised learning?\n",
    "In supervised learning, the model is trained using labelled data, where the input and corresponding output are known. The goal is to learn a mapping from input to output. In unsupervised learning, the model is trained on unlabeled data, and the goal is to discover patterns and relationships within the data without any specific output in mind.\n",
    "Example:\n",
    "Supervised Learning: Given a dataset with images of cats and dogs labeled as such, the model learns to classify new images as either cats or dogs based on the features it has learned from the labeled data.\n",
    "Unsupervised Learning: Given a dataset of customer behavior, the model identifies different customer segments without being told which segment each customer belongs to.\n",
    "Linear Regression and its assumption.\n",
    "Linear Regression:\n",
    "Definition: Linear regression is a statistical method used to find the relationship between two variables, where one variable is used to predict the other. It assumes that this relationship can be represented by a straight line equation.\n",
    "Example: Let's say you want to predict someone's salary based on their years of experience. In this case, years of experience is the predictor variable (X), and salary is the target variable (Y). Linear regression helps find the straight line (linear equation) that best fits the data to make predictions. For example, the equation might be:\n",
    "Salary = 10,000 + 2,000 * Years_of_Experience\n",
    "\n",
    "Linear Regression Assumptions:\n",
    "Linearity\n",
    "Definition: The relationship between the predictor variable (X) and the target variable (Y) should be linear, meaning it can be represented by a straight-line equation.\n",
    "Example: If we're predicting a person's weight (Y) based on their height (X), the relationship should roughly form a straight line on a scatterplot.\n",
    "\n",
    "Independence:\n",
    "Definition: Each data point should be independent, meaning the value of one data point should not be influenced by the value of another data point.\n",
    "Example: In a study of student test scores, the scores of one student should not be affected by the scores of other students.\n",
    "\n",
    "Homoscedasticity:\n",
    "Definition: The variability of the errors (differences between predicted and actual values) should be roughly constant across all levels of the predictor variable.\n",
    "Example: When predicting house prices based on their size, the differences between predicted and actual prices should have roughly the same spread for houses of different sizes.\n",
    "\n",
    "4. **Normality of Residuals:**\n",
    "   - **Definition:** The residuals (differences between predicted and actual values) should follow a normal distribution, forming a bell-shaped curve.\n",
    "   - **Example:** If we calculate the residuals when predicting test scores, those differences should follow a bell-shaped curve when plotted.\n",
    "\n",
    "5. **No or Little Multicollinearity:**\n",
    "   - **Definition:** The predictor variables should not be highly correlated with each other, as high correlation can lead to unstable coefficient estimates.\n",
    "   - **Example:** In a model predicting student performance, the variables for study hours and study group attendance should not be strongly correlated.\n",
    "\n",
    "6. **No Autocorrelation of Residuals:**\n",
    "   - **Definition:** The residuals should not show a pattern or relationship over time; they should be independent.\n",
    "   - **Example:** In a time-series analysis predicting stock prices, the residuals should not show a pattern of increasing or decreasing values over time.\n",
    "\n",
    "7. **Zero Mean of Residuals:**\n",
    "   - **Definition:** The average (mean) of the residuals should be close to zero.\n",
    "   - **Example:** If we calculate the residuals in a model predicting monthly expenses, the average of these differences should be near zero.\n",
    "\n",
    "These assumptions help ensure that the linear regression model is appropriate for the data and that the estimated coefficients are meaningful for making accurate predictions. Violations of these assumptions may require adjustments or a different modeling approach.\n",
    "\n",
    "How to Test the Assumptions of Linear Regression?\n",
    "L1 and L2 regularization - why does L1 lead to sparsity?\n",
    "Decision Tree - How to overcome the issue of overfitting in the decision trees? Tree-Pruning - How is it done?\n",
    "Bagging and Boosting - Random Forest, How random forest helps reduce high variance.\n",
    "KNN - pros and cons of KNN\n",
    "SVM and kernelization\n",
    "What is the linear and non-linear model? Why is logistic regression considered a linear model?\n",
    "PCA - dimensionality reduction, eigenvalues and eigenvectors.\n",
    "Data Missing - Imputation\n",
    "Regularisation\n",
    "PCA\n",
    "Regression\n",
    "K means\n",
    "Naive means in Naive Bayes\n",
    "If residual is not normally distribuetd , what will be your strategy\n",
    "Decision Boundary in Logistic and Decision Tree\n",
    "Correlation not zero, should we use\n",
    "Confusion Matrix\n",
    "Regularization\n",
    "F1 Score\n",
    "Precision and Recall\n",
    "Can you explain the variance in boosting and bagging?\n",
    "What is bias-variance tradeoff?\n",
    "\n",
    "What are bagging and boosting techniques?\n",
    "What is difference between C and gamma in SVM\n",
    "Whats the evaluation mertics for classification and regression model?bias and variance\n",
    " 1. Confusion Matrix 2. What is recall and precision? 3. Explain about ROC curve 4. Based on what RFE eliminate the features? 5. SQL question which requires grouping 6. How to read a dataframe, display top 5 rows, how to find summary statistics. 7. Probability question, rolling 3dice and find probability of getting all three even 8. Aptitude question, on percentage of poor group in a country.\n",
    "How to handle imbalanced data in text analytics?\n",
    "How to select features?\n",
    "Dummy Variable Trap\n",
    " What will be the approach If all the features are categorical in Linear Regression. Q3. What is Dummy variable trap? If we don't remove dummy variable what will be the issue and does it impact performance of the model?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
